{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../Functions/\")\n",
    "# sys.path.remove(\"../Functions/\")\n",
    "from getImageArrays import getExamples\n",
    "import getImageArrays\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloads source files to get most recent edits\n",
    "import importlib\n",
    "importlib.reload(getImageArrays)\n",
    "from getImageArrays import getExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_path = \"../Data/Logistic_Regression_Data/\"\n",
    "num_images = 100\n",
    "examples_per_batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getExamples!\n",
      "examplesCow (50, 100, 100, 3)\n",
      "../Data/Logistic_Regression_Data/notcows/ herererer\n",
      "Invalid shape notcow197.jpg\n",
      "examplesNotCow (50, 100, 100, 3)\n",
      "finished getImageArrays!\n",
      "lables_cow (50, 2)\n",
      "lables_notCow (50, 2)\n",
      "Examples Before (100, 100, 100, 3)\n",
      "labels Before (100, 2)\n",
      "Examples After (100, 100, 100, 3)\n",
      "labels After (100, 2)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = getExamples(side_length=100, image_path=image_path , test_ratio=.2, max_num_images=num_images)\n",
    "# train_x, train_y, test_x, test_y  = train_x.T, train_y.T, test_x.T, test_y.T\n",
    "assert((len(train_x) + len(test_x)) == num_images), \"Not sufficeint number of images\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBatches(x, examples_per_batch):\n",
    "    final = []\n",
    "    for i in range(0, len(x), examples_per_batch):\n",
    "        start = i\n",
    "        end = start + examples_per_batch\n",
    "        #creates exclusively\n",
    "        if end >= len(x):\n",
    "            return np.array(final)\n",
    "        final += [x[start:end]]\n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = createBatches(train_x, examples_per_batch), createBatches(train_y, examples_per_batch)\n",
    "test_x, test_y  = createBatches(test_x, examples_per_batch), createBatches(test_y, examples_per_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (4, 16, 100, 100, 3)\n",
      "train_y (4, 16, 2)\n",
      "test_x (1, 16, 100, 100, 3)\n",
      "test_y (1, 16, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x\", train_x.shape)\n",
    "print(\"train_y\", train_y.shape)\n",
    "print(\"test_x\", test_x.shape)\n",
    "print(\"test_y\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train_x = np.random.randn(1080, 64, 64, 3)\n",
    "train_y = np.random.randn(1080, 6)\n",
    "test_x = np.random.randn(120, 64, 64, 3)\n",
    "test_y = np.random.randn(120, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(width, height, channels, num_output_classes):\n",
    "    placeholder_x = tf.placeholder(tf.float32, shape=(None, width, height, channels))\n",
    "    placeholder_y = tf.placeholder(tf.float32, shape=(None, num_output_classes))\n",
    "    return placeholder_x, placeholder_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "placeholder_x, placeholder_y = create_placeholders(64, 64, 3, 2)\n",
    "print(placeholder_x)\n",
    "print(placeholder_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params():\n",
    "    tf.set_random_seed(1)\n",
    "    #shape = (window_height, window_width, prev_channels, new_channels)\n",
    "    W1 = tf.get_variable(\"W1\", shape=[4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", shape=[2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    #tf takes care of biases\n",
    "    return {\"W1\": W1,\"W2\":W2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394\n",
      " -0.06847463  0.05245192]\n",
      "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
      " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
      " -0.22779644 -0.1601823  -0.16117483 -0.10286498]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    params = initialize_params()\n",
    "    initialize = tf.global_variables_initializer()\n",
    "    sess.run(initialize)\n",
    "    print(params[\"W1\"].eval()[1, 1, 1])\n",
    "    print(params[\"W2\"].eval()[1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394\n",
    " -0.06847463  0.05245192]\n",
    "[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n",
    " -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n",
    " -0.22779644 -0.1601823  -0.16117483 -0.10286498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foward_propagate(x, params):\n",
    "    #tf useses params deduce meta data about architecture\n",
    "    W1 = params[\"W1\"]\n",
    "    W2 = params[\"W2\"]\n",
    "    \n",
    "    # Layer 1: Convolution -> Relu -> Max Pool\n",
    "    z1 = tf.nn.conv2d(x, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    a1 = tf.nn.relu(z1)\n",
    "    p1 = tf.nn.max_pool(a1, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding=\"SAME\")\n",
    "    \n",
    "    # Layer 2: Convolution -> Relu -> Max Pool\n",
    "    z2 = tf.nn.conv2d(p1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "    a2 = tf.nn.relu(z2)\n",
    "    p2 = tf.nn.max_pool(a2, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding=\"SAME\")\n",
    "    \n",
    "    # \n",
    "    flatten_cnn_output = tf.contrib.layers.flatten(p2)\n",
    "    preds = tf.contrib.layers.fully_connected(flatten_cnn_output, 2, activation_fn=None)\n",
    "    \n",
    "    return preds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.44169843 -0.24909666  5.45049906 -0.26189619 -0.20669907  1.36546707]\n",
      " [ 1.40708458 -0.02573211  5.08928013 -0.48669922 -0.40940708  1.26248586]]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(17)\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    placeholder_x, placeholder_y = create_placeholders(64, 64, 3, 6)\n",
    "    params = initialize_params()\n",
    "    preds = foward_propagate(placeholder_x, params)\n",
    "    initialize = tf.global_variables_initializer()\n",
    "    sess.run(initialize)\n",
    "    test = sess.run(preds, {placeholder_x: np.random.randn(2, 64, 64, 3), placeholder_y: np.random.randn(2, 6)})\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[ 1.44169843 -0.24909666  5.45049906 -0.26189619 -0.20669907  1.36546707]\n",
    " [ 1.40708458 -0.02573211  5.08928013 -0.48669922 -0.40940708  1.26248586]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_op(preds, y):\n",
    "    costs = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=y)\n",
    "    #gets average\n",
    "    avg_cost = tf.reduce_mean(costs)\n",
    "#     avg_cost = tf.abs(avg_cost)\n",
    "#     costs = tf.abs(costs)\n",
    "#     avg_cost = tf.reduce_mean(costs)\n",
    "    print(\"COSTS\", costs)\n",
    "    print(\"AVG Cost\", avg_cost)\n",
    "    return avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be same size: logits_size=[4,1] labels_size=[4,6]\n\t [[Node: softmax_cross_entropy_with_logits_sg = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](softmax_cross_entropy_with_logits_sg/Reshape, softmax_cross_entropy_with_logits_sg/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_with_logits_sg', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-92-227a3e99b644>\", line 9, in <module>\n    avg_cost = cost_op(preds, placeholder_y)\n  File \"<ipython-input-91-da74c87ec1e2>\", line 2, in cost_op\n    costs = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=y)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 250, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1960, in softmax_cross_entropy_with_logits\n    labels=labels, logits=logits, dim=dim, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1875, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4575, in _softmax_cross_entropy_with_logits\n    name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[4,1] labels_size=[4,6]\n\t [[Node: softmax_cross_entropy_with_logits_sg = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](softmax_cross_entropy_with_logits_sg/Reshape, softmax_cross_entropy_with_logits_sg/Reshape_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be same size: logits_size=[4,1] labels_size=[4,6]\n\t [[Node: softmax_cross_entropy_with_logits_sg = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](softmax_cross_entropy_with_logits_sg/Reshape, softmax_cross_entropy_with_logits_sg/Reshape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-227a3e99b644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mplaceholder_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be same size: logits_size=[4,1] labels_size=[4,6]\n\t [[Node: softmax_cross_entropy_with_logits_sg = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](softmax_cross_entropy_with_logits_sg/Reshape, softmax_cross_entropy_with_logits_sg/Reshape_1)]]\n\nCaused by op 'softmax_cross_entropy_with_logits_sg', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-92-227a3e99b644>\", line 9, in <module>\n    avg_cost = cost_op(preds, placeholder_y)\n  File \"<ipython-input-91-da74c87ec1e2>\", line 2, in cost_op\n    costs = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=y)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 250, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1960, in softmax_cross_entropy_with_logits\n    labels=labels, logits=logits, dim=dim, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1875, in softmax_cross_entropy_with_logits_v2\n    precise_logits, labels, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4575, in _softmax_cross_entropy_with_logits\n    name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[4,1] labels_size=[4,6]\n\t [[Node: softmax_cross_entropy_with_logits_sg = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](softmax_cross_entropy_with_logits_sg/Reshape, softmax_cross_entropy_with_logits_sg/Reshape_1)]]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(17)\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    placeholder_x, placeholder_y = create_placeholders(64, 64, 3, 6)\n",
    "    params = initialize_params()\n",
    "    preds = foward_propagate(placeholder_x, params)\n",
    "    print(preds.shape)\n",
    "    avg_cost = cost_op(preds, placeholder_y)\n",
    "    \n",
    "    initialize = tf.global_variables_initializer()\n",
    "    sess.run(initialize)\n",
    "    \n",
    "    test = sess.run(avg_cost, {placeholder_x: np.random.randn(4, 64, 64, 3), placeholder_y: np.random.randn(4, 6)})\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(trainX, trainY, testX, testY, epoch, lr, output_num_classes):\n",
    "    ops.reset_default_graph()\n",
    "#     tf.set_random_seed(17)\n",
    "    num_batches, num_train_examples , width, height, num_channels = trainX.shape\n",
    "    _, num_test_examples , _, _, _ = testX.shape\n",
    "#     output_num_classes = 1\n",
    "    costs = []\n",
    "    \n",
    "    # Conv -> ....\n",
    "    placeholder_x, placeholder_y = create_placeholders(width, height, num_channels, output_num_classes)\n",
    "    params = initialize_params()\n",
    "    preds = foward_propagate(placeholder_x, params)\n",
    "    spred = (placeholder_y, preds)\n",
    "    avg_cost = cost_op(preds, placeholder_y)\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(avg_cost)\n",
    "    \n",
    "    initialize = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(initialize)\n",
    "        \n",
    "        for i in range(epoch):\n",
    "                #remember to shuffle batches\n",
    "            for b in range(num_batches):\n",
    "    #         mini_batch_cost = 0\n",
    "    #         num_mini_batches = int(num_train_examples/batch_size)\n",
    "\n",
    "    #         mini_batch_cost = sess.run(avg_cost, {placeholder_x: np.random.randn(4, 64, 64, 3), placeholder_y: np.random.randn(4, 6)})\n",
    "    #         costs += mini_batch_cost\n",
    "    \n",
    "\n",
    "                cur_cost = sess.run([optimizer, preds, avg_cost, spred], {placeholder_x: trainX[b], placeholder_y: trainY[b]})\n",
    "#                 print(\"preds\", preds)\n",
    "                costs += [cur_cost[2]]\n",
    "            if i % 20 == 0:\n",
    "                print(\"Avg recent costs\", sum(costs[-20:]) / 20)\n",
    "#                 print(\"Spred\", cur_cost[3])\n",
    "        predict = tf.argmax(preds, 1)\n",
    "        true_label = tf.argmax(placeholder_y, 1)\n",
    "        correct = tf.equal(predict, true_label)\n",
    "    \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, \"float\"))\n",
    "        train_acc = accuracy.eval({placeholder_x: trainX[0], placeholder_y: trainY[0]})\n",
    "        test_acc = accuracy.eval({placeholder_x: testX[0], placeholder_y: testY[0]})\n",
    "        print(\"accuracy\", accuracy)\n",
    "        print(\"train_acc\", train_acc)\n",
    "        print(\"test_acc\", test_acc)\n",
    "    \n",
    "    x = [i for i in range(len(costs))]\n",
    "    y = costs\n",
    "    plt.plot(x, y)\n",
    "    plt.ylabel(\"cost\")\n",
    "    plt.xlabel(\"iters\")\n",
    "#     plt.titl\n",
    "    plt.show()\n",
    "    \n",
    "    return sess\n",
    "    \n",
    "#     return train_acc, test_acc, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (4, 16, 100, 100, 3)\n",
      "train_y (4, 16, 2)\n",
      "test_x (1, 16, 100, 100, 3)\n",
      "test_y (1, 16, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x\", train_x.shape)\n",
    "print(\"train_y\", train_y.shape)\n",
    "print(\"test_x\", test_x.shape)\n",
    "print(\"test_y\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COSTS Tensor(\"Reshape_2:0\", shape=(?,), dtype=float32)\n",
      "AVG Cost Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Avg recent costs 0.137735959888\n",
      "Avg recent costs 0.103109914809\n",
      "Avg recent costs 0.00856989331078\n",
      "Avg recent costs 0.00266801022808\n",
      "Avg recent costs 0.00131443661812\n"
     ]
    }
   ],
   "source": [
    "sess = model(train_x, train_y, test_x, test_y, 100, .005, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
