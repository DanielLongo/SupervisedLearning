{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Vanilla Neural Net "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROJECT ROADMAP TO-DOs\n",
    "\n",
    "- [] Flush out deep NN model, try adding 3-5 *layers*, and experiment with different sizes of those layers. Take it to the extremes, and try adding ~10+ layers to see how that changes the model.\n",
    "\n",
    "- [ ] Graph out accuracies of shallow AND deep models \n",
    "\n",
    "- [x] Explore the ideas of precision / recall, F1 score (read up about this). Write functions to calculate precision() and recall() for your models. Run these functions on ShallowNN, Logistic model, and DeepNN. Write function to compute F1 score -- compute_f1_score(), and run the same tests.\n",
    "\n",
    "- [] Tune and *graph* different hyper-parameter experiments (lr, epoch, etc). \n",
    "\n",
    "- [] Try training on another data set (this can be another image set OR non-image data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image classifer with logistic regression\n",
    "#images shape(width,height,3(rgb))\n",
    "\n",
    "###to knit to html ipython nbconvert --to html [NEWFILENAME].html\n",
    "import numpy as np\n",
    "import scipy \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import sys\n",
    "#from basicFunctions import crossEntropyLoss \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Constants\n",
    "side_length = 100\n",
    "image_path = \"../Data/Logistic_Regression_Data/\"\n",
    "test_ratio = .3\n",
    "epoch = 7000\n",
    "learning_rate = .2\n",
    "max_num_images = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImageArrays(path, side_length): #returns list of images arrays for a specified path\n",
    "    image_names = os.listdir(path)\n",
    "    image_names = image_names[:max_num_images]\n",
    "    examples = []\n",
    "    for image_name in image_names:\n",
    "        if image_name.split(\".\")[-1] != \"DS_Store\":\n",
    "            try:\n",
    "                cur_image_path = path + image_name\n",
    "                cur_image = np.array(ndimage.imread(cur_image_path,flatten=False))\n",
    "                cur_array_resized = scipy.misc.imresize(cur_image,size=(side_length,side_length))\n",
    "                cur_array_flattened = cur_array_resized.reshape((side_length*side_length*3)).T\n",
    "\n",
    "                examples += [cur_array_flattened] \n",
    "            except ValueError:\n",
    "                print(\"Error in creating examples\",image_name)\n",
    "                \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in creating examples notcow197.jpg\n",
      "Error in creating examples notcow20.jpg\n",
      "Number of Examples: 596\n",
      "Number of Labels: 596\n"
     ]
    }
   ],
   "source": [
    "#create examples & labels\n",
    "cow_images_path = image_path + \"cows/\"\n",
    "notCow_image_path = image_path + \"notcows/\"\n",
    "\n",
    "examples_cow = getImageArrays(cow_images_path, side_length)\n",
    "labels_cow = np.ones(len(examples_cow))\n",
    "examples_notCow = getImageArrays(notCow_image_path, side_length)\n",
    "labels_notCow = np.zeros(len(examples_notCow))\n",
    "\n",
    "examples_cow = np.array(examples_cow)\n",
    "examples_notCow = np.array(examples_notCow)\n",
    "#assert(examples_cow.shape[1:] == (side_length,side_length,3)), \"examples_cow are invalid shape\"\n",
    "examples = np.concatenate((examples_cow,examples_notCow))\n",
    "labels = np.concatenate((labels_cow,labels_notCow))\n",
    "print(\"Number of Examples:\",len(examples))\n",
    "print(\"Number of Labels:\",len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_indexing = np.random.permutation(labels.shape[0])\n",
    "examples = examples[shuffled_indexing]\n",
    "labels = labels[shuffled_indexing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  (30000, 418)\n",
      "Number of test examples:  (30000, 178)\n",
      "(418,)\n"
     ]
    }
   ],
   "source": [
    "#seperate train and test examples\n",
    "number_examples_test = int(len(examples)*test_ratio)\n",
    "number_labels_test = int(len(labels)*test_ratio)\n",
    "\n",
    "examples_test = examples[:number_examples_test]\n",
    "examples_train = examples[number_examples_test:]\n",
    "labels_test = labels[:number_labels_test]\n",
    "labels_train = labels[number_labels_test:]\n",
    "print(\"Number of training examples: \", examples_train.T.shape)\n",
    "print(\"Number of test examples: \", examples_test.T.shape)\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reshape labels for future matrix operations\n",
    "labels_train = np.reshape(labels_train,(1,len(labels_train)))\n",
    "labels_test = np.reshape(labels_test,(1,len(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#flatten examples\n",
    "# flattened_train_examples = examples_train.reshape(examples_train.shape[0], -1).T\n",
    "# flattened_test_examples = examples_test.reshape(examples_test.shape[0], -1).T  \n",
    "# print(\"flattened examples\",flattened_test_examples.shape,flattened_train_examples.shape)\n",
    "flattened_train_examples = examples_train.T\n",
    "flattened_test_examples = examples_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized (30000, 178) (30000, 418)\n"
     ]
    }
   ],
   "source": [
    "# Standardize color values of the image (decrease computational cost durring cross entropy)\n",
    "standardized_train_examples = flattened_train_examples/255 #225 is the maximum rgb value/ This is done to decrease varaince in inputs thus more efficint\n",
    "standardized_test_examples = flattened_test_examples/255\n",
    "print(\"standardized\",standardized_test_examples.shape,standardized_train_examples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossEntropyLoss(a,Y):\n",
    "    num_of_examples = Y.shape[1] #len(Y) doesn't work, need 2nd dimesnion\n",
    "    a = a.T\n",
    "    loss = - (1.0 / num_of_examples) * (np.dot((1.0 - Y), np.log(1.0 - a)) + np.dot(Y, np.log(a)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    output = 1.0/(1.0+np.exp(-x))\n",
    "    cached_value = x\n",
    "    cached_value = {\"out_a\":x}\n",
    "    return output, cached_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x,leaky=0):\n",
    "    output = np.maximum(leaky,x)\n",
    "#     cached_value = x\n",
    "    cached_value = {\"out_a\":x}\n",
    "    return output, cached_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params_shallow(input_layer, hidden_layer, output_layer):\n",
    "    w1 = np.random.randn(hidden_layer,input_layer)\n",
    "    w2 = np.random.randn(output_layer,hidden_layer)\n",
    "    #np.random.randn gives numbers larger than 1 so: (vanishing/exploading gradients)\n",
    "    w1,w2 = w1 * .01, w2 * .01\n",
    "    \n",
    "    #is it by one because of broadcasting \n",
    "    b1 = np.zeros((hidden_layer,1))\n",
    "    b2 = np.zeros((output_layer,1))\n",
    "    \n",
    "    assert(w1.shape == (hidden_layer, input_layer))\n",
    "    assert(w2.shape == (output_layer, hidden_layer))\n",
    "    assert(b1.shape == (hidden_layer,1))\n",
    "    assert(b2.shape == (output_layer,1))\n",
    "    \n",
    "    return {\"w1\":w1,\"w2\":w2,\"b1\":b1,\"b2\":b2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_params_deep(input_layer, hidden_layers, output_layer):\n",
    "#     np.random.seed(3) #non random random numbers (will get the same random numbers each time) used for testing\n",
    "    layers = {} #dictionary of weights and biasis\n",
    "    previous_layer = input_layer #sets the begining shape as shape of input layer\n",
    "    for i in range(len(hidden_layers)):\n",
    "        cur_layer = hidden_layers[i]\n",
    "        weights = np.random.randn(cur_layer,previous_layer)\n",
    "        weights *= .01 #because np.random.rand returns numbers too large, more efficeint durring gradient descensed \n",
    "        bias = np.zeros((cur_layer,1))\n",
    "        cur_weights_key = \"w\" + str(i + 1) # i + 1 because humans like things indexed at 0\n",
    "        cur_bias_key = \"b\" + str(i + 1)\n",
    "        layers[cur_weights_key] = weights\n",
    "        layers[cur_bias_key] = bias \n",
    "        \n",
    "        assert(layers[\"w\" + str(i + 1)].shape == (cur_layer, previous_layer))\n",
    "        assert(layers[\"b\" + str(i + 1)].shape == (cur_layer,1))\n",
    "        \n",
    "        previous_layer = cur_layer\n",
    "\n",
    "    layers[\"w\" + str(len(hidden_layers) + 1)] = np.random.randn(output_layer,previous_layer) * .01\n",
    "    layers[\"b\" + str(len(hidden_layers) + 1)] = np.zeros((output_layer,1))\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_forward_prop(a,w,b): #a because a is from the past layer\n",
    "#     print(\"Before Transpose -- A:\",a.shape,\"W:\",w.shape,\"B:\",b.shape)\n",
    "#     print(\"After Transpose -- A:\",a.shape,\"W:\",w.shape,\"B:\",b.shape)\n",
    "    z = np.dot(w,a) + b\n",
    "#     print(\"z:\",z.shape)\n",
    "#     print(\"z\",z.shape,\"a\",a.shape[0],\"w\",w.shape[1],\"b\",b.shape)\n",
    "#     assert(z.shape == (a.shape[0], w.shape[1] ))\n",
    "    #     assert(z.shape == np.dot(a,w).shape)\n",
    "    cached_inputs = {\"in_a\":a,\"w\":w,\"b\":b,\"z\":z} #(a,w,b)\n",
    "    return z,cached_inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def singleFowardPropagation(X,w,b,activationType,leaky=0): #TODO change x to a\n",
    "#     cached_inputs = {\"w\":None,\"x\":None,\"b\":None,\"z\":None}\n",
    "    z,cached_values = linear_forward_prop(X,w,b)\n",
    "    if activationType == \"sigmoid\":\n",
    "        a, activation_cache = sigmoid(z)\n",
    "    if activationType == \"relu\":\n",
    "        a, activation_cache = relu(z,leaky=leaky)\n",
    "    cached_values.update(activation_cache)\n",
    "    return a, cached_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fowardPropagate(X,params):\n",
    "    num_layers = len(params) // 2 #// rounds down\n",
    "    #assert len params is even\n",
    "    a = X\n",
    "    cached_values = []\n",
    "    for i in range(1,num_layers):\n",
    "        w = params[\"w\" + str(i)]\n",
    "        b = params[\"b\" + str(i)]\n",
    "        past_a = a\n",
    "        a, cur_cached = singleFowardPropagation(past_a,w,b,\"relu\")\n",
    "        cached_values += [cur_cached] #TODO: get foramt of cached values \n",
    "        \n",
    "    w = params[\"w\" + str(num_layers)]\n",
    "    b = params[\"b\" + str(num_layers)]\n",
    "    a, cur_cached = singleFowardPropagation(a,w,b,\"sigmoid\")\n",
    "    cached_values += [cur_cached] \n",
    "    #write assert statemt here\n",
    "    return a, cached_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearBackprop(cached_values, dZ):\n",
    "    a = cached_values[\"in_a\"]\n",
    "    w = cached_values[\"w\"]\n",
    "    b = cached_values[\"b\"]\n",
    "    number_examples = a.shape[1]\n",
    "    dW = (1.0/number_examples) * np.dot(dZ,a.T)\n",
    "    dB = (1.0/number_examples) * np.sum(dZ, axis = 1, keepdims= True)\n",
    "    dA = np.dot(w.T, dZ)\n",
    "    return {\"dW\":dW,\"dB\":dB,\"dA\":dA}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, z):\n",
    "    dZ = np.array(dA, copy=True) #convert dA to np array\n",
    "    dZ[z <= 0] = 0\n",
    "    return dZ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, z):\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    dz = dA * s * (1-s) \n",
    "    \n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backwards_activation(dA, cached_values, activation_type):\n",
    "    if activation_type == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, cached_values[\"z\"])\n",
    "    if activation_type == \"relu\":\n",
    "        dZ = relu_backward(dA, cached_values[\"z\"])\n",
    "    gradients = linearBackprop(cached_values, dZ)\n",
    "    return gradients\n",
    "    \n",
    "    #todo write optimizer function\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop(a, cached_values, y):\n",
    "    gradients = {}\n",
    "    num_layers = len(cached_values)\n",
    "    y = y.reshape(a.shape)\n",
    "\n",
    "    dFinalA = -(np.divide(y,a) - np.divide(1-y, 1-a)) #dervivative of output of foward pass \n",
    "    backwards_activation_output_0 = backwards_activation(dFinalA, cached_values[-1],\"sigmoid\")\n",
    "    \n",
    "    gradients[\"dW\" + str(num_layers)] = backwards_activation_output_0[\"dW\"]\n",
    "    gradients[\"dB\" + str(num_layers)] = backwards_activation_output_0[\"dB\"]\n",
    "    gradients[\"dA\" + str(num_layers - 1)] = backwards_activation_output_0[\"dA\"]\n",
    "    \n",
    "    for i in reversed(range(num_layers - 1)):\n",
    "        past_layer = cached_values[i]\n",
    "        cur_dLayer = backwards_activation(gradients[\"dA\" + str(i + 1)], past_layer, \"relu\")\n",
    "        gradients[\"dW\" + str(i + 1)] = cur_dLayer[\"dW\"]\n",
    "        gradients[\"dB\" + str(i + 1)] = cur_dLayer[\"dB\"]\n",
    "        gradients[\"dA\" + str(i)] = cur_dLayer[\"dA\"]\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(grads,params, learning_rate):\n",
    "    num_layers = len(params)//2\n",
    "    for i in range(num_layers): #subtraction\n",
    "#         print(\"lr\",learning_rate)\n",
    "#         print(\"w-before (\", str(i+1), \"): \", params[\"w\" + str(i +1)])\n",
    "#         print(\"b-before (\", str(i+1), \"): \", params[\"b\" + str(i +1)])\n",
    "#         print(\"------------\")\n",
    "#         print(\"dW\",grads[\"dW\" + str(i + 1)])\n",
    "#         print(\"dB\",grads[\"dB\" + str(i + 1)])\n",
    "        params[\"w\" + str(i +1)] = params[\"w\" + str(i + 1)] - (grads[\"dW\" + str(i + 1)] * learning_rate)\n",
    "        params[\"b\" + str(i + 1)] = params[\"b\" + str(i + 1)] - (grads[\"dB\" + str(i + 1)] * learning_rate)\n",
    "#         print(\"w-after (\", str(i+1), \"): \", params[\"w\" + str(i +1)])\n",
    "#         print(\"b-after (\", str(i+1), \"): \", params[\"b\" + str(i +1)])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = 12288 #change to side length*length*3 \n",
    "hidden_layer = 7\n",
    "output_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallowNN(X,y,epoch,lr,input_layer,hidden_layer,output_layer):\n",
    "    params = initialize_params_shallow(input_layer,hidden_layer,output_layer)\n",
    "    costs = []\n",
    "    grads = {}\n",
    "    for i in range(epoch):\n",
    "        w1 = params[\"w1\"]\n",
    "        w2 = params[\"w2\"]\n",
    "        b1 = params[\"b1\"]\n",
    "        b2 = params[\"b2\"]\n",
    "        a1, cached_values1 = singleFowardPropagation(X,w1,b1,\"relu\")\n",
    "        a2, cached_values2 = singleFowardPropagation(a1,w2,b2,\"sigmoid\")\n",
    "        # backwards [end] (1,710) --> (7,710) --> (exmample size,710) [start]\n",
    "        cost = crossEntropyLoss(a2,y)\n",
    "        dFinalA = -(np.divide(y,a2) - np.divide(1.0-y, 1.0-a2))\n",
    "#         print(\"dfinal a\", dFinalA.shape)\n",
    "        backwards_activation_output_0 = backwards_activation(dFinalA, cached_values2,\"sigmoid\")\n",
    "#         print(\"penultimate activation\",np.shape(backwards_activation_output_0[\"dA\"]))\n",
    "        backwards_activation_output_1 = backwards_activation(backwards_activation_output_0[\"dA\"], cached_values1,\"relu\")\n",
    "#         print(\"last activation\",np.shape(backwards_activation_output_1[\"dA\"]))\n",
    "        grads[\"dW1\"] = backwards_activation_output_1[\"dW\"]\n",
    "        grads[\"dW2\"] = backwards_activation_output_0[\"dW\"]\n",
    "        grads[\"dB1\"] = backwards_activation_output_1[\"dB\"]\n",
    "        grads[\"dB2\"] = backwards_activation_output_0[\"dB\"]\n",
    "        params = optimize(grads, params, learning_rate)\n",
    "        \n",
    "        costs += [cost]\n",
    "        if i % 100 == 0:\n",
    "            print(\"Costs @ \" + str(i) + \":\",cost)    \n",
    "    return params, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shallowNNTest(X,y,params):\n",
    "    w1 = params[\"w1\"]\n",
    "    w2 = params[\"w2\"]\n",
    "    b1 = params[\"b1\"]\n",
    "    b2 = params[\"b2\"]\n",
    "    a1, cached_values1 = singleFowardPropagation(X,w1,b1,\"relu\")\n",
    "    a2, cached_values2 = singleFowardPropagation(a1,w2,b2,\"sigmoid\")\n",
    "    loss = 1 - np.mean(np.abs(a2-y))\n",
    "    print(\"Test Accuracey:\",loss * 100,\"%\")\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs @ 0: [[ 0.69252566]]\n",
      "Costs @ 100: [[ 0.6403955]]\n",
      "Costs @ 200: [[ 0.50176175]]\n",
      "Costs @ 300: [[ 0.4987403]]\n",
      "Costs @ 400: [[ 0.4446108]]\n",
      "Costs @ 500: [[ 0.41360502]]\n",
      "Costs @ 600: [[ 0.40492271]]\n",
      "Costs @ 700: [[ 0.36510672]]\n",
      "Costs @ 800: [[ 0.34548186]]\n",
      "Costs @ 900: [[ 0.30250976]]\n",
      "Costs @ 1000: [[ 0.20765576]]\n",
      "Costs @ 1100: [[ 0.17029188]]\n",
      "Costs @ 1200: [[ 0.14568449]]\n",
      "Costs @ 1300: [[ 0.12733834]]\n",
      "Costs @ 1400: [[ 0.10749311]]\n",
      "Costs @ 1500: [[ 0.0926972]]\n",
      "Costs @ 1600: [[ 0.10048525]]\n",
      "Costs @ 1700: [[ 0.07078047]]\n",
      "Costs @ 1800: [[ 0.05521385]]\n",
      "Costs @ 1900: [[ 0.04458302]]\n"
     ]
    }
   ],
   "source": [
    "X = standardized_train_examples\n",
    "y = labels_train\n",
    "input_layer = side_length * side_length * 3\n",
    "hidden_layer = 7\n",
    "output_layer = 1\n",
    "learning_rate = .01\n",
    "params,costs = shallowNN(X,y,2000,learning_rate,input_layer,hidden_layer,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracey: 73.4149795332 %\n"
     ]
    }
   ],
   "source": [
    "X = standardized_test_examples\n",
    "y = labels_test\n",
    "loss = shallowNNTest(X,y,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepNN(X,y,epoch,lr,input_layer,hidden_layers,output_layer):\n",
    "    params = initialize_params_deep(input_layer,hidden_layers,output_layer)\n",
    "    costs = []\n",
    "    print(\"params\",len(params))\n",
    "    for i in range(epoch):\n",
    "        a, cache = fowardPropagate(X,params)\n",
    "        cost = crossEntropyLoss(a,y)\n",
    "        grads = backprop(a, cache, y)\n",
    "        params = optimize(grads, params, lr)\n",
    "        if i % 200 == 0:\n",
    "            print(\"Cost @\",i,cost)\n",
    "        costs += [cost]\n",
    "    return params,costs\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#works only for binary classification\n",
    "def precision(preds,y):\n",
    "    preds = np.abs(np.round(preds))\n",
    "    p_predict = np.sum(preds) #number of positives \n",
    "    tP = np.sum(preds*y)\n",
    "    return tP/p_predict\n",
    "\n",
    "def recall(preds,y):\n",
    "    preds = np.abs(np.round(preds))\n",
    "    tP = np.sum(preds*y)\n",
    "    new_preds = np.array(preds)\n",
    "    new_preds[new_preds == 0] = -1\n",
    "    #all 0 are now -1 in preds\n",
    "    product = new_preds * y\n",
    "    # after multiplying the only -1s left are false negatives\n",
    "    fN = len(product[product == -1])\n",
    "    return tP / (tP + fN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepNNEval(X, y, params):\n",
    "    a, _ = fowardPropagate(X,params)\n",
    "    loss = np.mean(np.abs(a-y))\n",
    "    precision_score = precision(a,y)\n",
    "    recall_score = recall(a,y)\n",
    "    print(\"Loss:\", loss)\n",
    "    print(\"Percision:\", precision_score)\n",
    "    print(\"Recall:\", recall_score)\n",
    "    return loss, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost @ 0 [[ 0.69314594]]\n",
      "Cost @ 200 [[ 0.69267378]]\n",
      "Cost @ 400 [[ 0.69249364]]\n",
      "Cost @ 600 [[ 0.69241607]]\n",
      "Cost @ 800 [[ 0.69236703]]\n",
      "Cost @ 1000 [[ 0.69230957]]\n",
      "Cost @ 1200 [[ 0.69220046]]\n",
      "Cost @ 1400 [[ 0.69191943]]\n",
      "Cost @ 1600 [[ 0.69091971]]\n",
      "Cost @ 1800 [[ 0.68572704]]\n",
      "Cost @ 2000 [[ 0.65553093]]\n",
      "Cost @ 2200 [[ 0.58673277]]\n",
      "Cost @ 2400 [[ 0.48766775]]\n",
      "Cost @ 2600 [[ 0.41945736]]\n",
      "Cost @ 2800 [[ 0.3421487]]\n",
      "Cost @ 3000 [[ 0.28894341]]\n",
      "Cost @ 3200 [[ 0.22854561]]\n",
      "Cost @ 3400 [[ 0.75844304]]\n",
      "Cost @ 3600 [[ 0.13287533]]\n",
      "Cost @ 3800 [[ 0.11074437]]\n",
      "Cost @ 4000 [[ 0.06864941]]\n",
      "Cost @ 4200 [[ 0.05149643]]\n",
      "Cost @ 4400 [[ 0.03810955]]\n",
      "Cost @ 4600 [[ 0.02992505]]\n",
      "Cost @ 4800 [[ 0.02383721]]\n"
     ]
    }
   ],
   "source": [
    "X = standardized_train_examples\n",
    "y = labels_train\n",
    "input_layer = side_length * side_length * 3\n",
    "hidden_layers = [7, 5]\n",
    "output_layer = 1\n",
    "learning_rate = .01\n",
    "params, costs = deepNN(X,y,5000,learning_rate,input_layer,hidden_layers,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.273606551433\n",
      "Percision: 0.767676767677\n",
      "Recall: 0.775510204082\n"
     ]
    }
   ],
   "source": [
    "X = standardized_test_examples\n",
    "y = labels_test\n",
    "loss,_,_ = deepNNEval(X,y,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImage(image_path,side_length,show=True):\n",
    "    if (image_path.split(\":\")[0] == \"http\") or (image_path.split(\":\")[0] == \"https\"):\n",
    "        try:\n",
    "            image = io.imread(image_path)\n",
    "        except:\n",
    "            print(\"Sorry, but this url forbids requests from machines :(\")\n",
    "            assert(5 == 4)\n",
    "    else:\n",
    "        image = np.array(ndimage.imread(image_path, flatten=False))\n",
    "    if show == True:\n",
    "        io.imshow(image)\n",
    "        io.show()\n",
    "    array_resized = scipy.misc.imresize(image, size=(side_length,side_length))\n",
    "    array_flattened = array_resized.reshape((side_length*side_length*3, 1))\n",
    "    array_standardized = array_flattened/225\n",
    "    return array_standardized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(image_path, params):\n",
    "    side_length = int((params[\"w1\"].shape[1]/3) ** .5)\n",
    "    image_array = getImage(image_path, side_length)\n",
    "    label,_ = fowardPropagate(image_array,params)\n",
    "    if round(label[0][0]) == 1:\n",
    "        print(\"Mœ\",label[0][0])\n",
    "    if round(label[0][0]) == 0:\n",
    "        print(\"This is not a cow\",label[0][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_costs(run_costs,label=None):\n",
    "    run_costs = np.array(run_costs) #makes costs one array instead of list of arrays\n",
    "    run_costs = np.squeeze(run_costs)\n",
    "    print(\"Run Costs\",run_costs[:20])\n",
    "    sample_timestep = 1\n",
    "    x = np.arange(0,len(run_costs),sample_timestep) \n",
    "    plt.plot(x, run_costs, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_runs(train_X,train_Y,test_X,test_Y, run_params, intput_layer): \n",
    "    test_losses = []\n",
    "    for run in run_params:\n",
    "        cur_learning_rate = run[\"learning_rate\"]\n",
    "        cur_epoch = run[\"epoch\"]\n",
    "        cur_hidden = run[\"hidden\"]\n",
    "        print(\"Run {epoch: \" + str(cur_epoch) + \", lr: \" + str(cur_learning_rate) + \", hidden: \" + str(cur_hidden) + \"}\")\n",
    "        cur_params, cur_costs = deepNN(train_X,train_Y,cur_epoch, cur_learning_rate, input_layer, cur_hidden,1)\n",
    "        cur_label = \"epoch: \" + str(cur_epoch) + \", lr: \" + str(cur_learning_rate) + \", hidden: \" + str(cur_hidden) + \"\"\n",
    "        cur_test_loss = deepNNEval(test_X,test_Y,cur_params)\n",
    "#         print(:cur)\n",
    "        test_losses += [cur_test_loss]\n",
    "        plot_costs(cur_costs,cur_label)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    return test_losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run {epoch: 100, lr: 0.01, hidden: [10, 20, 4, 8, 3]}\n",
      "params 12\n",
      "Cost @ 0 [[ 0.69314718]]\n",
      "0.50042866861 0.449438202247\n",
      "Run Costs [ 0.69314718  0.69314352  0.69313988  0.69313625  0.69313265  0.69312906\n",
      "  0.69312549  0.69312194  0.69311841  0.69311489  0.6931114   0.69310792\n",
      "  0.69310445  0.69310101  0.69309758  0.69309417  0.69309077  0.69308739\n",
      "  0.69308403  0.69308069]\n",
      "Run {epoch: 100, lr: 0.1, hidden: [7, 5, 3]}\n",
      "params 8\n",
      "Cost @ 0 [[ 0.69314719]]\n",
      "0.501781214933 0.449438202247\n",
      "Run Costs [ 0.69314719  0.69311101  0.69307662  0.69304394  0.69301286  0.69298332\n",
      "  0.69295524  0.69292855  0.69290317  0.69287905  0.69285611  0.69283431\n",
      "  0.69281359  0.69279389  0.69277516  0.69275736  0.69274043  0.69272434\n",
      "  0.69270905  0.69269451]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqcAAAEKCAYAAAAvj/ypAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110355320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = standardized_train_examples\n",
    "train_y = labels_train\n",
    "test_X = standardized_test_examples\n",
    "test_y = labels_test\n",
    "run_params = [\n",
    "    {\"learning_rate\":.01,\"epoch\":100,\"hidden\":[10,20,4,8,3]},\n",
    "    {\"learning_rate\":.1,\"epoch\":100,\"hidden\":[7,5,3]}\n",
    "]\n",
    "input_layer = side_length*side_length*3\n",
    "losses = compare_runs(train_X, train_y, test_X, test_y, run_params, input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
